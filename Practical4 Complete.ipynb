{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0844e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea0351d3",
   "metadata": {},
   "source": [
    "\n",
    "Name: Harsh Zanwar\n",
    "Roll No.: 74\n",
    "Branch:CSE(AIML)\n",
    "\n",
    "Aim:4(a) Write a Python NLTK program to perform Stemming and Lemmatization on set of tokens.\n",
    "PorterStemmer(), \n",
    "SnowballStemmer(), \n",
    "LancasterStemmer(), \n",
    "RegexpStemmer(),\n",
    "WordNetLemmatizer(),\n",
    "lemmatizer.lemmatize()\n",
    "\n",
    "4(b) Write a program to perform Morphological generation on different surface forms of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b6b5319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token\t\tPOS\tPorter Stemmer\tSnowball Stemmer\tLancaster Stemmer\tRegexp Stemmer\tWordNet Lemmatizer\n",
      "playing\t\tVBG\tplay\t\tplay\t\t\t\tplay\t\tplay\t\tplay\n",
      "played\t\tVBD\tplay\t\tplay\t\t\t\tplay\t\tplay\t\tplay\n",
      "plays\t\tVBZ\tplay\t\tplay\t\t\t\tplay\t\tplays\t\tplay\n",
      "player\t\tNN\tplayer\t\tplayer\t\t\t\tplay\t\tplayer\t\tplayer\n",
      "jumps\t\tVBZ\tjump\t\tjump\t\t\t\tjump\t\tjumps\t\tjump\n",
      "jumping\t\tVBG\tjump\t\tjump\t\t\t\tjump\t\tjump\t\tjump\n",
      "jumped\t\tVBD\tjump\t\tjump\t\t\t\tjump\t\tjump\t\tjump\n",
      "jumper\t\tNN\tjumper\t\tjumper\t\t\t\tjump\t\tjumper\t\tjumper\n",
      "running\t\tVBG\trun\t\trun\t\t\t\trun\t\trunn\t\trun\n",
      "ran\t\tVBD\tran\t\tran\t\t\t\tran\t\tran\t\trun\n",
      "runs\t\tVBZ\trun\t\trun\t\t\t\trun\t\truns\t\trun\n",
      "runner\t\tNN\trunner\t\trunner\t\t\t\trun\t\trunner\t\trunner\n",
      "eating\t\tVBG\teat\t\teat\t\t\t\teat\t\teat\t\teat\n",
      "ate\t\tVBD\tate\t\tate\t\t\t\tat\t\tate\t\teat\n",
      "eats\t\tVBZ\teat\t\teat\t\t\t\teat\t\teats\t\teat\n",
      "eater\t\tNN\teater\t\teater\t\t\t\teat\t\teater\t\teater\n",
      "talking\t\tVBG\ttalk\t\ttalk\t\t\t\ttalk\t\ttalk\t\ttalk\n",
      "talked\t\tVBD\ttalk\t\ttalk\t\t\t\ttalk\t\ttalk\t\ttalk\n",
      "talks\t\tVBZ\ttalk\t\ttalk\t\t\t\ttalk\t\ttalks\t\ttalk\n",
      "talker\t\tNN\ttalker\t\ttalker\t\t\t\ttalk\t\ttalker\t\ttalker\n",
      "singing\t\tVBG\tsing\t\tsing\t\t\t\tsing\t\tsing\t\tsing\n",
      "sang\t\tVBD\tsang\t\tsang\t\t\t\tsang\t\tsang\t\tsing\n",
      "sings\t\tVBZ\tsing\t\tsing\t\t\t\tsing\t\tsings\t\tsing\n",
      "singer\t\tNN\tsinger\t\tsinger\t\t\t\tsing\t\tsinger\t\tsinger\n",
      "writing\t\tVBG\twrite\t\twrite\t\t\t\twrit\t\twrit\t\twrite\n",
      "wrote\t\tVBD\twrote\t\twrote\t\t\t\twrot\t\twrote\t\twrite\n",
      "writes\t\tVBZ\twrite\t\twrite\t\t\t\twrit\t\twrites\t\twrite\n",
      "writer\t\tNN\twriter\t\twriter\t\t\t\twrit\t\twriter\t\twriter\n",
      "swimming\t\tVBG\tswim\t\tswim\t\t\t\tswim\t\tswimm\t\tswim\n",
      "swam\t\tVBD\tswam\t\tswam\t\t\t\tswam\t\tswam\t\tswim\n",
      "swims\t\tVBZ\tswim\t\tswim\t\t\t\tswim\t\tswims\t\tswim\n",
      "swimmer\t\tNN\tswimmer\t\tswimmer\t\t\t\tswim\t\tswimmer\t\tswimmer\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample sets of tokens with different POS tags\n",
    "tokens = [(\"playing\", \"VBG\"), (\"played\", \"VBD\"), (\"plays\", \"VBZ\"), (\"player\", \"NN\"), \n",
    "          (\"jumps\", \"VBZ\"), (\"jumping\", \"VBG\"), (\"jumped\", \"VBD\"), (\"jumper\", \"NN\"), \n",
    "          (\"running\", \"VBG\"), (\"ran\", \"VBD\"), (\"runs\", \"VBZ\"), (\"runner\", \"NN\"), \n",
    "          (\"eating\", \"VBG\"), (\"ate\", \"VBD\"), (\"eats\", \"VBZ\"), (\"eater\", \"NN\"), \n",
    "          (\"talking\", \"VBG\"), (\"talked\", \"VBD\"), (\"talks\", \"VBZ\"), (\"talker\", \"NN\"), \n",
    "          (\"singing\", \"VBG\"), (\"sang\", \"VBD\"), (\"sings\", \"VBZ\"), (\"singer\", \"NN\"), \n",
    "          (\"writing\", \"VBG\"), (\"wrote\", \"VBD\"), (\"writes\", \"VBZ\"), (\"writer\", \"NN\"), \n",
    "          (\"swimming\", \"VBG\"), (\"swam\", \"VBD\"), (\"swims\", \"VBZ\"), (\"swimmer\", \"NN\")]\n",
    "\n",
    "# Initialize stemmers and lemmatizer\n",
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "regexp_stemmer = RegexpStemmer(\"ing$|ed$\", min=4)\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Perform stemming and lemmatization on the tokens using different stemmers and lemmatizer\n",
    "print(\"Token\\t\\tPOS\\tPorter Stemmer\\tSnowball Stemmer\\tLancaster Stemmer\\tRegexp Stemmer\\tWordNet Lemmatizer\")\n",
    "for token in tokens:\n",
    "    word = token[0]\n",
    "    pos = token[1]\n",
    "    porter = porter_stemmer.stem(word)\n",
    "    snowball = snowball_stemmer.stem(word)\n",
    "    lancaster = lancaster_stemmer.stem(word)\n",
    "    regexp = regexp_stemmer.stem(word)\n",
    "    lemma = wordnet_lemmatizer.lemmatize(word, pos=pos.lower()[0])\n",
    "    print(f\"{word}\\t\\t{pos}\\t{porter}\\t\\t{snowball}\\t\\t\\t\\t{lancaster}\\t\\t{regexp}\\t\\t{lemma}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddddd20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surface Form\tBase Form\n",
      "running\t\trun\n",
      "runs\t\trun\n",
      "ran\t\trun\n",
      "runner\t\trunner\n",
      "eaten\t\teat\n",
      "ate\t\teat\n",
      "eating\t\teat\n",
      "eater\t\teater\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Sample surface forms of a word\n",
    "surface_forms = [\"running\", \"runs\", \"ran\", \"runner\", \"eaten\", \"ate\", \"eating\", \"eater\"]\n",
    "\n",
    "# Perform morphological generation on the surface forms\n",
    "print(\"Surface Form\\tBase Form\")\n",
    "for surface_form in surface_forms:\n",
    "    base_form = lemmatizer.lemmatize(surface_form, pos='v')\n",
    "    print(f\"{surface_form}\\t\\t{base_form}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee1207e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf06ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0099b3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statemachine\n",
      "  Downloading statemachine-0.1.tar.gz (1.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: statemachine\n",
      "  Building wheel for statemachine (setup.py): started\n",
      "  Building wheel for statemachine (setup.py): finished with status 'done'\n",
      "  Created wheel for statemachine: filename=statemachine-0.1-py3-none-any.whl size=1843 sha256=bcc43d62165dbeb1064c1e35b1faec57b4e8422cd585b899598808aae793840b\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\51\\98\\63\\50f3917901b2239e5eb40f728ec73cb7403f50e81ca21a0691\n",
      "Successfully built statemachine\n",
      "Installing collected packages: statemachine\n",
      "Successfully installed statemachine-0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install statemachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275aef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
